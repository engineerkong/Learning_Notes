# Study Plan

## Plan and manage an Azure AI solution (15–20%)
### Select the appropriate Azure AI service
- Select the appropriate service for a computer vision solution
- Select the appropriate service for a natural language processing solution
- Select the appropriate service for a decision support solution
- Select the appropriate service for a speech solution
- Select the appropriate service for a generative AI solution
- Select the appropriate service for a document intelligence solution
- Select the appropriate service for a knowledge mining solution

### Plan, create and deploy an Azure AI service
- Plan for a solution that meets Responsible AI principles
- Create an Azure AI resource
- Determine a default endpoint for a service
- Integrate Azure AI services into a continuous integration and continuous delivery (CI/CD) pipeline
- Plan and implement a container deployment

### Manage, monitor and secure an Azure AI service
- Configure diagnostic logging
- Monitor an Azure AI resource
- Manage costs for Azure AI services
- Manage account keys
- Protect account keys by using Azure Key Vault
- Manage authentication for an Azure AI Service resource
- Manage private communications

## Implement decision support solutions (10–15%)
### Create decision support solutions for data monitoring and anomaly detection
- Implement a univariate anomaly detection solution with Azure AI Anomaly Detector
- Implement a multivariate anomaly detection solution Azure AI Anomaly Detector
- Implement a data monitoring solution with Azure AI Metrics Advisor

### Create decision support solutions for content delivery
- Implement a text moderation solution with Azure AI Content Safety
- Implement an image moderation solution with Azure AI Content Safety
- Implement a content personalization solution with Azure AI Personalizer

## Implement computer vision solutions (15–20%)
### Analyze images
- Select visual features to meet image processing requirements
- Detect objects in images and generate image tags
- Include image analysis features in an image processing request
- Interpret image processing responses
- Extract text from images using Azure AI Vision
- Convert handwritten text using Azure AI Vision

### Implement custom computer vision models by using Azure AI Vision
- Choose between image classification and object detection models
- Label images
- Train a custom image model, including image classification and object detection
- Evaluate custom vision model metrics
- Publish a custom vision model
- Consume a custom vision model

### Analyze videos
- Use Azure AI Video Indexer to extract insights from a video or live stream
- Use Azure AI Vision Spatial Analysis to detect presence and movement of people in video

## Implement natural language processing solutions (30–35%)
### Analyze text by using Azure AI Language
- Extract key phrases
- Extract entities
- Determine sentiment of text
- Detect the language used in text
- Detect personally identifiable information (PII) in text

### Process speech by using Azure AI Speech
- Implement text-to-speech
- Implement speech-to-text
- Improve text-to-speech by using Speech Synthesis Markup Language (SSML)
- Implement custom speech solutions
- Implement intent recognition
- Implement keyword recognition

### Translate language
- Translate text and documents by using the Azure AI Translator service
- Implement custom translation, including training, improving, and publishing a custom model
- Translate speech-to-speech by using the Azure AI Speech service
- Translate speech-to-text by using the Azure AI Speech service
- Translate to multiple languages simultaneously

### Implement and manage a language understanding model by using Azure AI Language
- Create intents and add utterances
- Create entities
- Train, evaluate, deploy, and test a language understanding model
- Optimize a language understanding model
- Consume a language model from a client application
- Backup and recover language understanding models

### Create a question answering solution by using Azure AI Language
- Create a question answering project
- Add question-and-answer pairs manually
- Import sources
- Train and test a knowledge base
- Publish a knowledge base
- Create a multi-turn conversation
- Add alternate phrasing
- Add chit-chat to a knowledge base
- Export a knowledge base
- Create a multi-language question answering solution

## Implement knowledge mining and document intelligence solutions (10–15%)
### Implement an Azure Cognitive Search solution
- Provision a Cognitive Search resource
- Create data sources
- Create an index
- Define a skillset
- Implement custom skills and include them in a skillset
- Create and run an indexer
- Query an index, including syntax, sorting, filtering, and wildcards
- Manage Knowledge Store projections, including file, object, and table projections

### Implement an Azure AI Document Intelligence solution
- Provision a Document Intelligence resource
- Use prebuilt models to extract data from documents
- Implement a custom document intelligence model
- Train, test, and publish a custom document intelligence model
- Create a composed document intelligence model
- Implement a document intelligence model as a custom Azure Cognitive Search skill

## Implement generative AI solutions (10–15%)
### Use Azure OpenAI Service to generate content
- Provision an Azure OpenAI Service resource
- Select and deploy an Azure OpenAI model
- Submit prompts to generate natural language
- Submit prompts to generate code
- Use the DALL-E model to generate images
- Use Azure OpenAI APIs to submit prompts and receive responses

### Optimize generative AI
- Configure parameters to control generative behavior
- Apply prompt engineering techniques to improve responses
- Use your own data with an Azure OpenAI model
- Fine-tune an Azure OpenAI model

# Learning Path

- Artifical Intelligence <- Machine Learning <- Data Science
- 1. Fairness 2. Reliability and Safety 3. Privacy and Security 4. Inclusiveness 5. Transparency 6. Accountability
- Decision support: Content safety, Content moderation
- Computer vision: Image analysis, Video analysis, Image classification, Object detection, Facial analysis, Optical character recognition, Azure AI Video Indexer
- Natural Language Processing: Text analysis, Question answering, Language understanding, Translation, Named entity recognition, Custom text classification, Speech, Speech Translation, Speech Translation
- Knowledge mining: AI Search, Custom skills
- Document intelligence: Document Intelligence, Custom Document Intelligence, 
- Generative AI: Azure OpenAI Service, DALL-E image generation
- 1. The endpoint URI 2. A subscription key 3. The resource location
- REST interfaces: submitting and receiving JSON over HTTP
- Software development kits (SDKs): abstract the REST interfaces for most AI services
- authentication: Key Vault, Token-based authentication, Microsoft Entra ID authentication.
- Network Security: an error that access is denied due to Virtual Network/Firewall rules - in Networking properties, add your client IP address to the Firewall allowed list.
### Monitor Azure AI services
- Cost (Cost management), Alerts (Alerts in resource), Metrics (Metrics in resource, Dashboard Hub), Diagnostic logging (Diagnostic settings in resource, Azure Log Anlaytics)

- Container Images from Registry
- Object Detection in Cusom Vision:
Tags: "apple"
Left: 0.1
Top: 0.5
Width: 0.5
Height: 0.25
- The Azure AI Vision service enables you to detect people in an image, as well as returning a bounding box for its location.
- The Face service offers more comprehensive facial analysis capabilities than the Azure AI Vision service, including: Face detection (with bounding box). Comprehensive facial feature analysis (including head pose, presence of spectacles, blur, facial landmarks, occlusion and others). Face comparison and verification. Facial recognition.
- The Azure AI Vision service offers two APIs that you can use to read text. The Read API. The Image Anlysis API. The results of from the Read API are broken down by page, then line, and then word.
- The Azure Video Indexer service is designed to help you extract information from videos. Facial recognition, Optical character recognition, Speech transcription, Topics, Sentiment, Labels, Content moderation, Scene segmentation. Azure Video Indexer includes predefined models that can recognize well-known celebrities, do OCR, and transcribe spoken phrases into text. You can extend the recognition capabilities of Video Analyzer by creating custom models for: People, Language, Brands. Using Azure Video Indexer widgets and Azure Video Indexer API.
- Azure AI Language is designed to help you extract information from text. It provides functionality that you can use for: Language Detection, Key Phrase extration, sentiment analysis, Named entity recognition, Entity linking.
- The knowledge base can be created from existing sources, including: Web sites containing frequently asked question (FAQ) documentation. Files containing structured text, such as brochures or user guides. Built-in chit chat question and answer pairs that encapsulate common conversational exchanges.
- Language understanding: Service uses natural language understanding to interpret the utterance, match it to an intent, and identify entities. Response indicates the most likely intent and referenced entities.
- This kind of interaction is referred to as a multi-turn conversation.
- People often ask questions that are phrased differently, but ultimately have the same meaning. Active learning can help in situations like this because it enables you to consider alternate questions to each question and answer pair. Active learning is enabled by default. Active learning then begins to offer alternate questions for each question in your question and answer pairs. 
- a natural language understanding solution:
1. An app accepts natural language input from a user.
2. A language model is used to determine semantic meaning (the user's intent).
3. The app performs an appropriate action.
- Azure AI Language service features fall into two categories: Pre-configured features, and Learned features.
- Personally identifiable information (PII) detection: allows you to identify, categorize, and redact information that could be considered sensitive.
- CLU helps users to build custom natural language understanding models to predict overall intent and extract important information from incoming utterances.
- Utterances are the phrases that a user might enter when interacting with an application that uses your language model. An intent represents a task or action the user wants to perform, or more simply the meaning of an utterance. You create a model by defining intents and associating them with one or more utterances.
- The precision, consistency and completeness of your labeled data are key factors to determining model performance. Entities are used to add specific context to intents. For example, you might define a TurnOnDevice intent that can be applied to multiple devices, and use entities to define the different devices. 1. Learned 2. List 3. Prebuilt "Turn off the {DeviceName}" Train_Test_Deploy_Review
- Custom text classification: Single label classification, Multiple label classification
- Recall: Of all the actual labels, how many were identified; the ratio of true positives to all that was labeled.
- Precision: How many of the predicted labels are correct; the ratio of true positives to all identified positives.
- Custom NER enables developers to extract predefined entities from text documents, without those documents being in a known format, such as legal agreements or online ads. Custom NER focus of the rest of common NER. An entity is a person, place, thing, event, skill, or value.
- The Azure AI Translator provides an API for translating text between 90 supported languages. Language detection, One-to-many translation, Script transliteration.
- `curl -X POST "https://api.cognitive.microsofttranslator.com/translate?api-version=3.0&from=ja&to=fr&to=en" -H "Ocp-Apim-Subscription-Key: <your-key>" -H "Ocp-Apim-Subscription-Region: <your-service-region>" -H "Content-Type: application/json; charset=UTF-8" -d "[{ 'Text' : 'こんにちは' }]"`
- Parameters: includeAlignment, includeSentenceLength
- Azure Speech: Speech to text, Text to speech, Speech Translation, Speaker Recognition, Intent Recognition. Speech Synthesis Markup Language (SSML).
- Use the SpeechConfig and AudioConfig to create a SpeechRecognizer object. This object is a proxy client for the Speech to text API. includes the following properties: Duration, OffsetInTicks, Properties, Reason, ResultId, Text.
- Use the SpeechConfig and AudioConfig to create a SpeechSynthesizer object, contains the following properties: AudioData, Properties, Reason, ResultId.
- Translation of speech builds on speech recognition by recognizing and transcribing spoken input in a specified language, and returning translations of the transcription in one or more other languages.
- The SpeechTranslationConfig object is also used to specify the speech recognition language and the target languages. Use an AudioConfig to define the input source for the audio to be transcribed. Using event-based synthesis (event handler) or manual sythesis.
- In this example, you've used a SpeechTranslationConfig to translate speech to text, and then used a SpeechConfig to synthesize the translation as speech.
- `pip uninstall playsound pip install playsound==1.2.2`
- When translating speech, in which cases can you use the Synthesizing event to synthesize the translations and speech? You can only use event-based synthesis when translating to a single target language.
- Azure AI Search provides a cloud-based solution for indexing and querying a wide range of data sources, and creating comprehensive and high-scale search solutions. With Azure AI Search, you can: 1. Index documents and data from a range of sources. 2. Use cognitive skills to enrich index data. 3. Store extracted insights in a knowledge store for analysis and integration.
- a resource with four replicas and three partitions is using 12 search units.
- Indexing process: skillset, indexer, index. Query process: query parsing, lexical analysis, document retrieval, scoring. Filtering, sorting. 
- Search-as-you type (suggestions, autocomplete), scoring, synonoym.
- You want to find information in Microsoft Word documents that are stored in an Azure Storage blob container. What should you do to ensure the files can be accessed by Azure AI Search? In an Azure AI Services resource, and add a data source that references the container where the files are stored.
- A data source where the data to be indexed is stored (though you can also push data directly into an index by using the API). A skillset that defines and enrichment pipeline of cognitive skills to enrich the index data. An index that defines fields, which the user can query. An indexer that populates the fields in the index with values extracted from the source data.
- You want to include a sentiment score for each document in an index. What should you do? The built-in sentiment skill can be used to accomplish the goal in this scenario.
- Azure AI Search supports these scenarios by enabling you to define a knowledge store in the skillset that encapsulates your enrichment pipeline. The knowledge store consists of projections of the enriched data, which can be JSON objects, tables, or image files. When an indexer runs the pipeline to create or update an index, the projections are generated and persisted in the knowledge store.
- This Shaper skill creates a projection field to simplify the mapping of these field values to projections in a knowledge store. "knowledgeStore" object -> Object projections are JSON representations of the indexed documents. File projections are JPEG files containing image data extracted from documents. Table projections create a relational schema for the extracted data.
- Use Language Studio to enrich Azure Cognitive Search indexes.
- You right click on the function name in the Azure extension and select Copy function URL.
- Improve the ranking of a document with term boosting: query parsing `search=luxury + air con&$select=HotelId, HotelName, Category, Tags, Description&$count=true`
- Improve the relevance of results by adding scoring profiles:
- Improve an index with analyzers and tokenized terms:
- Using a machine learning custom skill works the same as adding any other custom skill to a search index (AmlSkill). Parameter: timeout and degreeOfParallelism. Steps: 1. Create Machine Learning Workspace 2. Train model 3. Edit scoring code 4. Create endpoint 5. Update cognitive search.
- The web service is the only supported endpoint for use with Azure Cognitive Search custom AML skill.
- Implementing batch size, threading, an exponential backoff retry strategy to improve index performance.
- The JSON can't contain complex data types like arrays by using the Azure Search linked service as a sink in a copy data task.
- Inbound search requests made by users to your search solution. Outbound requests from your search solution to other servers to index documents. Restricting access at the document level per user search request
- Semantic search is a capability within Azure Cognitive Search that aims to improve the ranking of search results. Semantic search improves the ranking of search results by using language understanding to more accurately match the context of the original query.
- BM25 ranking function Frequently
- Semantic search has two functions; it improves the ranking of the query results based on language understanding and it improves the response to the query by providing captions and answers in the results.
- Vector search is a new capability available in Cognitive Search used to index, store and retrieve vector embedding from a search index. A vector query can be used to match criteria across different types of source data by providing a mathematical representation of the content generated by machine learning models. This eliminates the limitations of text based searches returning relevant results by using the intent of the query.
- An embedding is type of data representation that is used by machine learning models. An embedding represents the semantic meaning of a piece of text. Embedding models and emedding space.
- Document Intelligence: 1. Prebuilt model: Read, General document, Layout 2. Custom model: custom template, custom neural 3. Composed model
- A Composed model consists of multiple custom models. Each submitted form is categorized as one of the custom form types and analyzed using the corresponding custom model.
- Selection marks record checkboxes and radio buttons and include whether they're selected or not.
- Since the document cracking stage happens before the skillset execution, it might prevent requests from reaching your custom skill.
- Azure OpenAI can make you more efficient and productive by generating code
- Responsible generative ai: identify, measure, mitigate, operate.
- Four layers to mitigate harms: model, safety system, metaprompt and grounding layer, user experience. Using content filters.
# References

## AI-102 Study Cram
## Updates
![image](https://github.com/engineerkong/Learning_Notes/assets/89781823/00b8926b-1e30-4610-82a6-717bb2af1aee)

pip install python-dotenv
https://mycontenmoderator238193.cognitiveservices.azure.com/
389e25833a604001a857829d4b40f99e
M.Sc.
https://westus.api.cognitive.microsoft.com/
e7ea9471363443f1ba092e195fd4d243
https://function3219873123.azurewebsites.net
2wailrcF-WgZOh0EN9Js8HLwxwA54WQ6MUliQDZa9ODbAzFufvFKXA==
Anspruch auf nicht Leistungsempfahger Gutscheine.
