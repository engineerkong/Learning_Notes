# Practices

- Security: 1. in keyvault store the keys 2. set up service principals
- 1. Alert: key viewing 2. Metrics: total call ...
- In container data will not passed to service. And can use local server to connect the container in order to use.

# Learning Path

## Get started with Azure AI Services
- Artifical Intelligence <- Machine Learning <- Data Science
- 1. Fairness 2. Reliability and Safety 3. Privacy and Security 4. Inclusiveness 5. Transparency 6. Accountability
- Decision support: Content safety, Content moderation
- Computer vision: Image analysis, Video analysis, Image classification, Object detection, Facial analysis, Optical character recognition, Azure AI Video Indexer
- Natural Language Processing: Text analysis, Question answering, Language understanding, Translation, Named entity recognition, Custom text classification, Speech, Speech Translation, Speech Translation
- Knowledge mining: AI Search, Custom skills
- Document intelligence: Document Intelligence, Custom Document Intelligence, 
- Generative AI: Azure OpenAI Service, DALL-E image generation
- 1. The endpoint URI 2. A subscription key 3. The resource location
- REST interfaces: submitting and receiving JSON over HTTP
- Software development kits (SDKs): abstract the REST interfaces for most AI services
- authentication: Key Vault, Token-based authentication, Microsoft Entra ID authentication.
- Network Security: an error that access is denied due to Virtual Network/Firewall rules - in Networking properties, add your client IP address to the Firewall allowed list.
- Cost (Cost management), Alerts (Alerts in resource), Metrics (Metrics in resource, Dashboard Hub), Diagnostic logging (Diagnostic settings in resource, Azure Log Anlaytics)
- Container Images from Registry

## Develop decision support solutions with Azure AI Services
- Text moderation: Profanity, Classisfication, Personal data
- AI Personalizer: reinforcement learning - Rank API, Reward API. Apprentice mode, Online mode. Inference explainability.

## Create computer vision solutions with Azure AI Vision
- Face detection: AI Vision service, Face service (Face detection, Face attribute analysis, Face landmark location, Face comparison, Face recognition, Face liveness).
- The most efficient approach to verify person is to compare the two faces using the detected face ID within 24 hours.

## Develop natural language processing solutions with Azure AI Services
- Pre-configured features: Summarization, Name entity recognition, Personally identifiable information detection, Key phrase extraction, Sentiment analysis, Language detection.
- Learned features: Conversational language understanding (CLU), Customed named entity recognition, Custom text classification, Question answering.
- Utterance: What is the time in London? Intent: DayofTime Entity: London
- Use patterns to differentiate similar utterances: GetDeviceStatus: "Is the {DeviceName} on[?]"
- Get the results of text classification task via API: Get the value from the operation-location header in the request response, and use that to retrieve the results of the classification request.
- custom named entity recognization vs built in NER
- Diverstity: You'll want to use sample data from as many sources as possible. Distribution: distribution of document types. Accuracy.
- Speech-enabled applications: Speech to text, Text to speech, Speech Translation, Speech Recognition, Intent Recognition.
- Speech Config + AudioConfig -> SpeechRecognizer/Speechsynthesizer

## Implement knowledge mining with Azure Cognitive Search
- Azure AI Search: Index documents and data from a range of sources. Use cognitive skills to enrich index data. Store extracted insights in a knowledge store for analysis and integration.
- Replicas are instances of the search service to ensure there is sufficient capacity to service multiple concurrent query requests .
- Partitions are used to divide an index into multiple storage locations.
- Skillset, Indexer, index
- Maps fields extracted from document content and metadata (in the fieldMappings section), and values extracted by skills in the skillset (in the outputFieldMappings section)
- Making a field searchable means that it can be queried for search terms. It does not mean the field can be included in the results. To enable a field to be included in the results, you must make it retrievable.
- Include the function App as a custom skill in the search solution skillset

- Object Detection in Cusom Vision:
Tags: "apple"
Left: 0.1
Top: 0.5
Width: 0.5
Height: 0.25
- The Azure AI Vision service enables you to detect people in an image, as well as returning a bounding box for its location.
- The Face service offers more comprehensive facial analysis capabilities than the Azure AI Vision service, including: Face detection (with bounding box). Comprehensive facial feature analysis (including head pose, presence of spectacles, blur, facial landmarks, occlusion and others). Face comparison and verification. Facial recognition.
- The Azure AI Vision service offers two APIs that you can use to read text. The Read API. The Image Anlysis API. The results of from the Read API are broken down by page, then line, and then word.
- The Azure Video Indexer service is designed to help you extract information from videos. Facial recognition, Optical character recognition, Speech transcription, Topics, Sentiment, Labels, Content moderation, Scene segmentation. Azure Video Indexer includes predefined models that can recognize well-known celebrities, do OCR, and transcribe spoken phrases into text. You can extend the recognition capabilities of Video Analyzer by creating custom models for: People, Language, Brands. Using Azure Video Indexer widgets and Azure Video Indexer API.
- Azure AI Language is designed to help you extract information from text. It provides functionality that you can use for: Language Detection, Key Phrase extration, sentiment analysis, Named entity recognition, Entity linking.
- The knowledge base can be created from existing sources, including: Web sites containing frequently asked question (FAQ) documentation. Files containing structured text, such as brochures or user guides. Built-in chit chat question and answer pairs that encapsulate common conversational exchanges.
- Language understanding: Service uses natural language understanding to interpret the utterance, match it to an intent, and identify entities. Response indicates the most likely intent and referenced entities.
- This kind of interaction is referred to as a multi-turn conversation.
- People often ask questions that are phrased differently, but ultimately have the same meaning. Active learning can help in situations like this because it enables you to consider alternate questions to each question and answer pair. Active learning is enabled by default. Active learning then begins to offer alternate questions for each question in your question and answer pairs. 
- a natural language understanding solution:
1. An app accepts natural language input from a user.
2. A language model is used to determine semantic meaning (the user's intent).
3. The app performs an appropriate action.
- Azure AI Language service features fall into two categories: Pre-configured features, and Learned features.
- Personally identifiable information (PII) detection: allows you to identify, categorize, and redact information that could be considered sensitive.
- CLU helps users to build custom natural language understanding models to predict overall intent and extract important information from incoming utterances.
- Utterances are the phrases that a user might enter when interacting with an application that uses your language model. An intent represents a task or action the user wants to perform, or more simply the meaning of an utterance. You create a model by defining intents and associating them with one or more utterances.
- The precision, consistency and completeness of your labeled data are key factors to determining model performance. Entities are used to add specific context to intents. For example, you might define a TurnOnDevice intent that can be applied to multiple devices, and use entities to define the different devices. 1. Learned 2. List 3. Prebuilt "Turn off the {DeviceName}" Train_Test_Deploy_Review
- Custom text classification: Single label classification, Multiple label classification
- Recall: Of all the actual labels, how many were identified; the ratio of true positives to all that was labeled.
- Precision: How many of the predicted labels are correct; the ratio of true positives to all identified positives.
- Custom NER enables developers to extract predefined entities from text documents, without those documents being in a known format, such as legal agreements or online ads. Custom NER focus of the rest of common NER. An entity is a person, place, thing, event, skill, or value.
- The Azure AI Translator provides an API for translating text between 90 supported languages. Language detection, One-to-many translation, Script transliteration.
- `curl -X POST "https://api.cognitive.microsofttranslator.com/translate?api-version=3.0&from=ja&to=fr&to=en" -H "Ocp-Apim-Subscription-Key: <your-key>" -H "Ocp-Apim-Subscription-Region: <your-service-region>" -H "Content-Type: application/json; charset=UTF-8" -d "[{ 'Text' : 'こんにちは' }]"`
- Parameters: includeAlignment, includeSentenceLength
- Azure Speech: Speech to text, Text to speech, Speech Translation, Speaker Recognition, Intent Recognition. Speech Synthesis Markup Language (SSML).
- Use the SpeechConfig and AudioConfig to create a SpeechRecognizer object. This object is a proxy client for the Speech to text API. includes the following properties: Duration, OffsetInTicks, Properties, Reason, ResultId, Text.
- Use the SpeechConfig and AudioConfig to create a SpeechSynthesizer object, contains the following properties: AudioData, Properties, Reason, ResultId.
- Translation of speech builds on speech recognition by recognizing and transcribing spoken input in a specified language, and returning translations of the transcription in one or more other languages.
- The SpeechTranslationConfig object is also used to specify the speech recognition language and the target languages. Use an AudioConfig to define the input source for the audio to be transcribed. Using event-based synthesis (event handler) or manual sythesis.
- In this example, you've used a SpeechTranslationConfig to translate speech to text, and then used a SpeechConfig to synthesize the translation as speech.
- `pip uninstall playsound pip install playsound==1.2.2`
- When translating speech, in which cases can you use the Synthesizing event to synthesize the translations and speech? You can only use event-based synthesis when translating to a single target language.
- Azure AI Search provides a cloud-based solution for indexing and querying a wide range of data sources, and creating comprehensive and high-scale search solutions. With Azure AI Search, you can: 1. Index documents and data from a range of sources. 2. Use cognitive skills to enrich index data. 3. Store extracted insights in a knowledge store for analysis and integration.
- a resource with four replicas and three partitions is using 12 search units.
- Indexing process: skillset, indexer, index. Query process: query parsing, lexical analysis, document retrieval, scoring. Filtering, sorting. 
- Search-as-you type (suggestions, autocomplete), scoring, synonoym.
- You want to find information in Microsoft Word documents that are stored in an Azure Storage blob container. What should you do to ensure the files can be accessed by Azure AI Search? In an Azure AI Services resource, and add a data source that references the container where the files are stored.
- A data source where the data to be indexed is stored (though you can also push data directly into an index by using the API). A skillset that defines and enrichment pipeline of cognitive skills to enrich the index data. An index that defines fields, which the user can query. An indexer that populates the fields in the index with values extracted from the source data.
- You want to include a sentiment score for each document in an index. What should you do? The built-in sentiment skill can be used to accomplish the goal in this scenario.
- Azure AI Search supports these scenarios by enabling you to define a knowledge store in the skillset that encapsulates your enrichment pipeline. The knowledge store consists of projections of the enriched data, which can be JSON objects, tables, or image files. When an indexer runs the pipeline to create or update an index, the projections are generated and persisted in the knowledge store.
- This Shaper skill creates a projection field to simplify the mapping of these field values to projections in a knowledge store. "knowledgeStore" object -> Object projections are JSON representations of the indexed documents. File projections are JPEG files containing image data extracted from documents. Table projections create a relational schema for the extracted data.
- Use Language Studio to enrich Azure Cognitive Search indexes.
- You right click on the function name in the Azure extension and select Copy function URL.
- Improve the ranking of a document with term boosting: query parsing `search=luxury + air con&$select=HotelId, HotelName, Category, Tags, Description&$count=true`
- Improve the relevance of results by adding scoring profiles:
- Improve an index with analyzers and tokenized terms:
- Using a machine learning custom skill works the same as adding any other custom skill to a search index (AmlSkill). Parameter: timeout and degreeOfParallelism. Steps: 1. Create Machine Learning Workspace 2. Train model 3. Edit scoring code 4. Create endpoint 5. Update cognitive search.
- The web service is the only supported endpoint for use with Azure Cognitive Search custom AML skill.
- Implementing batch size, threading, an exponential backoff retry strategy to improve index performance.
- The JSON can't contain complex data types like arrays by using the Azure Search linked service as a sink in a copy data task.
- Inbound search requests made by users to your search solution. Outbound requests from your search solution to other servers to index documents. Restricting access at the document level per user search request
- Semantic search is a capability within Azure Cognitive Search that aims to improve the ranking of search results. Semantic search improves the ranking of search results by using language understanding to more accurately match the context of the original query.
- BM25 ranking function Frequently
- Semantic search has two functions; it improves the ranking of the query results based on language understanding and it improves the response to the query by providing captions and answers in the results.
- Vector search is a new capability available in Cognitive Search used to index, store and retrieve vector embedding from a search index. A vector query can be used to match criteria across different types of source data by providing a mathematical representation of the content generated by machine learning models. This eliminates the limitations of text based searches returning relevant results by using the intent of the query.
- An embedding is type of data representation that is used by machine learning models. An embedding represents the semantic meaning of a piece of text. Embedding models and emedding space.
- Document Intelligence: 1. Prebuilt model: Read, General document, Layout 2. Custom model: custom template, custom neural 3. Composed model
- A Composed model consists of multiple custom models. Each submitted form is categorized as one of the custom form types and analyzed using the corresponding custom model.
- Selection marks record checkboxes and radio buttons and include whether they're selected or not.
- Since the document cracking stage happens before the skillset execution, it might prevent requests from reaching your custom skill.
- Azure OpenAI can make you more efficient and productive by generating code
- Responsible generative ai: identify, measure, mitigate, operate.
- Four layers to mitigate harms: model, safety system, metaprompt and grounding layer, user experience. Using content filters.
# References

## AI-102 Study Cram
## Updates
![image](https://github.com/engineerkong/Learning_Notes/assets/89781823/00b8926b-1e30-4610-82a6-717bb2af1aee)

pip install python-dotenv

Anspruch auf nicht Leistungsempfahger Gutscheine.

https://ai798949379.cognitiveservices.azure.com/
180214eef08443ada3a03c66741babcf
